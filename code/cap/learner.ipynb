{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-14T18:44:43.554857Z",
     "iopub.status.busy": "2021-12-14T18:44:43.554267Z",
     "iopub.status.idle": "2021-12-14T18:44:46.352718Z",
     "shell.execute_reply": "2021-12-14T18:44:46.351986Z",
     "shell.execute_reply.started": "2021-12-14T18:44:43.554761Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as tfs\n",
    "from torchvision.transforms import ToPILImage\n",
    "from torchvision.transforms import functional as FF\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import random\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-14T18:44:46.354702Z",
     "iopub.status.busy": "2021-12-14T18:44:46.354459Z",
     "iopub.status.idle": "2021-12-14T18:44:46.359088Z",
     "shell.execute_reply": "2021-12-14T18:44:46.358028Z",
     "shell.execute_reply.started": "2021-12-14T18:44:46.354671Z"
    }
   },
   "outputs": [],
   "source": [
    "config = {}\n",
    "config['batch_size'] = 64\n",
    "config['lr'] = 1e-3\n",
    "config['epochs'] = 100\n",
    "config['test_size'] = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-14T18:44:46.360792Z",
     "iopub.status.busy": "2021-12-14T18:44:46.360339Z",
     "iopub.status.idle": "2021-12-14T18:44:46.417689Z",
     "shell.execute_reply": "2021-12-14T18:44:46.416840Z",
     "shell.execute_reply.started": "2021-12-14T18:44:46.360755Z"
    }
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-14T18:44:46.420544Z",
     "iopub.status.busy": "2021-12-14T18:44:46.420210Z",
     "iopub.status.idle": "2021-12-14T18:44:46.427498Z",
     "shell.execute_reply": "2021-12-14T18:44:46.426807Z",
     "shell.execute_reply.started": "2021-12-14T18:44:46.420440Z"
    }
   },
   "outputs": [],
   "source": [
    "_DATA_PATH = '../input/indoor-training-set-its-residestandard'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-14T18:44:46.429415Z",
     "iopub.status.busy": "2021-12-14T18:44:46.428656Z",
     "iopub.status.idle": "2021-12-14T18:44:46.891786Z",
     "shell.execute_reply": "2021-12-14T18:44:46.891035Z",
     "shell.execute_reply.started": "2021-12-14T18:44:46.429378Z"
    }
   },
   "outputs": [],
   "source": [
    "list_hazy = glob(os.path.join(_DATA_PATH, \"hazy\", '*.png'))\n",
    "df_ = pd.DataFrame([])\n",
    "df_['hazy'] = list_hazy\n",
    "df_train, df_valid = train_test_split(df_, test_size = config['test_size'], random_state=42)\n",
    "df_train['is_train'] = True\n",
    "df_valid['is_train'] = False\n",
    "df_ = pd.concat([df_train, df_valid], axis=0).reset_index()\n",
    "df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-14T18:44:46.893617Z",
     "iopub.status.busy": "2021-12-14T18:44:46.892960Z",
     "iopub.status.idle": "2021-12-14T18:44:46.904487Z",
     "shell.execute_reply": "2021-12-14T18:44:46.903650Z",
     "shell.execute_reply.started": "2021-12-14T18:44:46.893577Z"
    }
   },
   "outputs": [],
   "source": [
    "class RESIDE_Dataset(Dataset):\n",
    "    def __init__(self, path, df_haze_imgs, size=240, format='.png'):\n",
    "        super(RESIDE_Dataset, self).__init__()\n",
    "        self.size = size\n",
    "        self.format = format\n",
    "        self.haze_imgs = list(df_haze_imgs['hazy'])\n",
    "        self.depth_imgs_dir = os.path.join(path,'trans').replace('\\\\','/')\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # depth = Image.open(self.depth_imgs[index])\n",
    "        haze_fname = self.haze_imgs[index]\n",
    "\n",
    "        haze = cv2.imread(haze_fname)\n",
    "        hazeHSV = cv2.cvtColor(haze, cv2.COLOR_BGR2HSV)\n",
    "        s = torch.tensor(hazeHSV[:,:,1] / 255.0)\n",
    "        v = torch.tensor(hazeHSV[:,:,2] / 255.0)\n",
    "        \n",
    "        id_ = '_'.join(haze_fname.split('/')[-1].split('_')[:2])\n",
    "        depth_fname = id_ + self.format\n",
    "        depth = Image.open(os.path.join(self.depth_imgs_dir, depth_fname))\n",
    "        depth = tfs.ToTensor()(depth)\n",
    "        depth = torch.squeeze(depth)\n",
    "        return s, v, depth\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.haze_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-14T18:44:46.906239Z",
     "iopub.status.busy": "2021-12-14T18:44:46.905964Z",
     "iopub.status.idle": "2021-12-14T18:44:46.932656Z",
     "shell.execute_reply": "2021-12-14T18:44:46.931721Z",
     "shell.execute_reply.started": "2021-12-14T18:44:46.906203Z"
    }
   },
   "outputs": [],
   "source": [
    "train_ds = RESIDE_Dataset(path = _DATA_PATH, df_haze_imgs = df_[df_['is_train']==True])\n",
    "valid_ds = RESIDE_Dataset(path = _DATA_PATH, df_haze_imgs = df_[df_['is_train']==False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-14T18:44:46.934398Z",
     "iopub.status.busy": "2021-12-14T18:44:46.934119Z",
     "iopub.status.idle": "2021-12-14T18:44:46.942006Z",
     "shell.execute_reply": "2021-12-14T18:44:46.939384Z",
     "shell.execute_reply.started": "2021-12-14T18:44:46.934330Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size = config['batch_size'])\n",
    "valid_dl = DataLoader(valid_ds, batch_size = config['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-14T18:44:46.944070Z",
     "iopub.status.busy": "2021-12-14T18:44:46.943810Z",
     "iopub.status.idle": "2021-12-14T18:44:49.743098Z",
     "shell.execute_reply": "2021-12-14T18:44:49.742100Z",
     "shell.execute_reply.started": "2021-12-14T18:44:46.944035Z"
    }
   },
   "outputs": [],
   "source": [
    "for s, v, d in train_dl:\n",
    "    # Image.open(x)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-14T18:44:49.748372Z",
     "iopub.status.busy": "2021-12-14T18:44:49.747898Z",
     "iopub.status.idle": "2021-12-14T18:44:49.756687Z",
     "shell.execute_reply": "2021-12-14T18:44:49.755770Z",
     "shell.execute_reply.started": "2021-12-14T18:44:49.748318Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "s.shape, v.shape, d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-14T18:44:49.759267Z",
     "iopub.status.busy": "2021-12-14T18:44:49.758537Z",
     "iopub.status.idle": "2021-12-14T18:44:49.805808Z",
     "shell.execute_reply": "2021-12-14T18:44:49.804880Z",
     "shell.execute_reply.started": "2021-12-14T18:44:49.759150Z"
    }
   },
   "outputs": [],
   "source": [
    "d.min(), d.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-14T18:44:49.808230Z",
     "iopub.status.busy": "2021-12-14T18:44:49.807892Z",
     "iopub.status.idle": "2021-12-14T18:44:49.820989Z",
     "shell.execute_reply": "2021-12-14T18:44:49.819850Z",
     "shell.execute_reply.started": "2021-12-14T18:44:49.808192Z"
    }
   },
   "outputs": [],
   "source": [
    "def init_model():\n",
    "    theta_0 = Variable(torch.tensor([0.]), requires_grad=True)\n",
    "    theta_1 = Variable(torch.tensor([1.]), requires_grad=True)\n",
    "    theta_2 = Variable(torch.tensor([-1.]), requires_grad=True)\n",
    "    model = theta_0, theta_1, theta_2\n",
    "    return model\n",
    "\n",
    "def forward_model(model, v, s):\n",
    "    theta_0, theta_1, theta_2 = model\n",
    "    d = theta_0 + theta_1 * v + theta_2 * s\n",
    "    return d, model\n",
    "\n",
    "def mse(t1, t2):\n",
    "    diff = t1 - t2\n",
    "    return (torch.sum(diff * diff) / diff.numel())\n",
    "\n",
    "def optimizer(theta, lr = config['lr']):\n",
    "    theta -= theta.grad * lr\n",
    "    theta.grad.zero_()\n",
    "    \n",
    "def evaluate(model, v, s, gt):\n",
    "    theta_0, theta_1, theta_2 = model\n",
    "    d_hat = theta_0 + theta_1 * v + theta_2 * s\n",
    "    d_hat = (d_hat*255).astype(np.uint8)\n",
    "    gt = (gt*255).astype(np.uint8)\n",
    "    psnr = compute_psnr(gt, d_hat)\n",
    "    ssim = compute_ssim(gt, d_hat)\n",
    "    return psnr, ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-14T18:44:49.823610Z",
     "iopub.status.busy": "2021-12-14T18:44:49.822818Z",
     "iopub.status.idle": "2021-12-14T18:44:49.842433Z",
     "shell.execute_reply": "2021-12-14T18:44:49.841528Z",
     "shell.execute_reply.started": "2021-12-14T18:44:49.823528Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_psnr(img_origin, img_denoise):\n",
    "    mse = np.mean((img_origin - img_denoise) ** 2)\n",
    "    if(mse == 0):\n",
    "        return 100\n",
    "    max_pixel = 255.0\n",
    "    psnr = 20 * np.log10(max_pixel / np.sqrt(mse))\n",
    "    return psnr\n",
    "\n",
    "def ssim(img1, img2):\n",
    "    C1 = (0.01 * 255)**2\n",
    "    C2 = (0.03 * 255)**2\n",
    "\n",
    "    img1 = img1.astype(np.float64)\n",
    "    img2 = img2.astype(np.float64)\n",
    "    kernel = cv2.getGaussianKernel(11, 1.5)\n",
    "    window = np.outer(kernel, kernel.transpose())\n",
    "\n",
    "    mu1 = cv2.filter2D(img1, -1, window)[5:-5, 5:-5]  # valid\n",
    "    mu2 = cv2.filter2D(img2, -1, window)[5:-5, 5:-5]\n",
    "    mu1_sq = mu1**2\n",
    "    mu2_sq = mu2**2\n",
    "    mu1_mu2 = mu1 * mu2\n",
    "    sigma1_sq = cv2.filter2D(img1**2, -1, window)[5:-5, 5:-5] - mu1_sq\n",
    "    sigma2_sq = cv2.filter2D(img2**2, -1, window)[5:-5, 5:-5] - mu2_sq\n",
    "    sigma12 = cv2.filter2D(img1 * img2, -1, window)[5:-5, 5:-5] - mu1_mu2\n",
    "\n",
    "    ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) *\n",
    "                                                            (sigma1_sq + sigma2_sq + C2))\n",
    "    return ssim_map.mean()\n",
    "\n",
    "\n",
    "def compute_ssim(img1, img2):\n",
    "    '''calculate SSIM\n",
    "    the same outputs as MATLAB's\n",
    "    img1, img2: [0, 255]\n",
    "    '''\n",
    "    if not img1.shape == img2.shape:\n",
    "        raise ValueError('Input images must have the same dimensions.')\n",
    "    if img1.ndim == 2:\n",
    "        return ssim(img1, img2)\n",
    "    elif img1.ndim == 3:\n",
    "        if img1.shape[2] == 3:\n",
    "            ssims = []\n",
    "            for i in range(3):\n",
    "                ssims.append(ssim(img1, img2))\n",
    "            return np.array(ssims).mean()\n",
    "        elif img1.shape[2] == 1:\n",
    "            return ssim(np.squeeze(img1), np.squeeze(img2))\n",
    "    else:\n",
    "        raise ValueError('Wrong input image dimensions.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-14T18:44:49.844276Z",
     "iopub.status.busy": "2021-12-14T18:44:49.843982Z",
     "iopub.status.idle": "2021-12-14T18:44:49.857364Z",
     "shell.execute_reply": "2021-12-14T18:44:49.856274Z",
     "shell.execute_reply.started": "2021-12-14T18:44:49.844239Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_one(model, train_dl, device):\n",
    "    losses = 0\n",
    "    for s, v, depth in tqdm(train_dl):\n",
    "        depth = depth.to(device)\n",
    "        depth_hat, model = forward_model(model, v, s)\n",
    "        depth_hat = depth_hat.to(device)\n",
    "        loss = mse(depth_hat, depth)\n",
    "#         print(loss)\n",
    "        losses += loss.item()\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            theta_0, theta_1, theta_2 = model\n",
    "            optimizer(theta_0)\n",
    "            optimizer(theta_1)\n",
    "            optimizer(theta_2)\n",
    "            model = theta_0, theta_1, theta_2\n",
    "    return losses/len(train_dl), model\n",
    "\n",
    "def eval_one(model, valid_dl, device):\n",
    "    losses = 0\n",
    "    psnrs = 0\n",
    "    ssims = 0\n",
    "    \n",
    "    count = 0\n",
    "    for s, v, depth in tqdm(valid_dl):\n",
    "        depth = depth.to(device)\n",
    "        depth_hat, model = forward_model(model, v, s)\n",
    "        depth_hat = depth_hat.to(device)\n",
    "        loss = mse(depth_hat, depth)\n",
    "        losses += loss.item()    \n",
    "    return losses/len(valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-14T18:44:49.859782Z",
     "iopub.status.busy": "2021-12-14T18:44:49.859387Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = init_model()\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "for epoch in range(config['epochs']):\n",
    "    train_loss, model = train_one(model, train_dl, device)\n",
    "    valid_loss = eval_one(model, valid_dl, device)\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    print('Epoch-{0}'.format(epoch))\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Valid Loss: {valid_loss:.3f}')\n",
    "    print('\\tParameters')\n",
    "    print(model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
